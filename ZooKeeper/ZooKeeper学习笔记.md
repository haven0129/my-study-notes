# ZooKeeper学习笔记

## 一致性级别

### 强一致性：用户体验好，性能较差

### 弱一致性

- 会话一致性：同一个客户端会话中读到一致的值
- 用户一致性：同一个用户中可以读到一致的值

### 最终一致性：一定时间内达到数据一致，弱一致性中的一个非常重要的模型，被业界大型分布式系统推崇

## 集中式到分布式

### 集中式

- 优点

	- 部署结构简单

- 缺点

	- 对服务器性能要求高

### 分布式

- 特点

	- 分布性：空间上随意分布
	- 对等性：计算机没有主从之分
	- 并发性：并发的操作一些共享资源

- 优点

	- 可靠性（容错）
	- 可扩展性
	- 资源共享
	- 更高的性能

- 缺点

	- 运维比较困难：部署包括问题排查
	- 安全性：存在数据安全性和共享的风险

## 事务

### ACID

- A（原子性）:事务里的一系列操作，要么都执行，要么都不执行
- C（一致性）：从一个一致性状态到另一个一致性状态（比如转账，不管转多少次，两个账户总金额是一样的）

  由原子性，隔离性，持久性最终来保证事务的一致性

- I（隔离性）：事务与事务之间互不干涉，跟串行执行是一样的结果

	- 隔离级别

		- 未授权读取（READ UNCOMMITTED）

			- 脏读

			  事务A读取了事务B中尚未提交的数据。如果事务B回滚，则A读取使用了错误的数据。

			- 不可重复读

			  不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。（修改）

			- 幻读

			  在事务A多次读取过程中，事务B对数据进行了新增操作，导致事务A多次读取的数据不一致。（增删）

		- 授权读取(READ COMMITTED)

			- 不可重复读
			- 幻读

		- 可重复读取(REPEATABLE READ)

			- 幻读

		- 串行化(SERIALIZABLE)

- D（持久性）：每次事务操作都是持久化的，即使系统挂了重启后还是事务执行后的结果（存到磁盘）

### CAP定理

- 一致性：数据在多个副本直接是否能保持一致
- 可用性：服务处于可用状态
- 分区容错性

### BASE理论

- 基本可用（系统故障时允许损失部分可用性）

	- 响应时间上的损失
	- 功能上的损失

- 弱状态：允许数据存在中间状态
- 最终一致性：允许经过一定时间后，数据最终达到一致状态

## 一致性协议

### 2PC

- 执行流程

	- 一、提交事务请求

		- 1、事务询问
		- 2、执行事务
		- 3、各参与者向协调者反馈事务查询的响应

	- 二、执行事务提交

		- 执行事务提交

			- 1、发送提交请求
			- 2、事务提交
			- 3、反馈事务提交结果
			- 4、完成事务

		- 中断事务

			- 1、发送回滚请求
			- 2、事务回滚
			- 3、反馈事务回滚结果
			- 4、中断事务

- 优点

	- 原理简单
	- 实现方便

- 缺点

	- 同步阻塞：等待响应过程中，无法进行其他操作
	- 单点问题：协调者只有一个，一旦出现问题，就会崩溃
	- 脑裂
	- 太过保守

### 3PC

- 执行流程

	- 一、CanCommit

		- 1、事务询问
		- 2、各参与者向协调者反馈事务询问的响应

	- 二、PreCommit

		- 执行事务预提交

			- 1、发送预提交请求
			- 2、事务预提交
			- 3、各参与者向协调者反馈事务执行的响应

		- 中断事务

			- 1、发送中断请求
			- 2、中断事务

	- 三、DoCommit

		- 执行提交

			- 1、发送提交请求
			- 2、事务提交
			- 3、反馈事务提交结果
			- 4、完成事务

		- 中断事务

			- 1、发送中断请求
			- 2、事务回滚
			- 3、反馈事务回滚结果
			- 4、中断事务

- 优点

	- 降低参与者的阻塞范围
	- 出现单点故障后能够继续达成一致

- 缺点

	- 参与者接收到PreCommit之后，如果些调整和参与者出现通信问题，参与者依然会提交事务，会导致数据不一致

## 分布式锁

### 场景

- 银行账户同时取款和转账
- 多个用户同时购物，库存不足的情况

### 分布式锁执行流程

- 1、获取锁
- 2、查看锁状态

  如果锁已被占用，则重试直到获取锁成功

- 3、给共享变量上锁
- 4、业务操作

  如果业务操作超时，那么自动释放锁

- 5、释放锁

### 分布式锁具备条件

- 互斥性

	- 同一时刻只有一个服务访问资源，特殊情况有读写锁

- 原子性

	- 要求加锁和解锁的流程是原子性的

- 安全性

	- 锁只能被持有该锁的服务释放

- 容错性

	- 持有锁的服务崩溃时，仍然能够释放锁，避免死锁

- 可重用性

	- 同一个服务获得锁后，可重复上锁（重入锁和不可重入锁），但是上多少次锁就要释放多少次锁

- 公平性

	- 看业务是否需要公平（公平锁和非公平锁）

- 支持阻塞和非阻塞

	- 阻塞

		- 获取锁的时候如果未获取到会一直循环获取

	- 非阻塞

		- 不会一直循环获取锁，尝试固定次数或时间后放弃

- 高可用

	- 获取和释放锁要高可用

- 高性能

	- 获取和释放锁性能要好（速度快）

- 持久性

	- 按业务需要允许锁的持有者对锁的有效期进行自动续约/自动延期（比如业务执行需要10s，但是锁的有效期只有2s的情况）

### 实现方式

- 基于数据库实现

	- 基于数据库表（基于唯一约束）

		- 实现步骤

			- 1、访问数据时，将程序编号插入表
			- 2、如果插入成功，就表示获得了锁
			- 3、当其他程序插入时，由于插入相同程序编号，导致插入失败就表示获取锁失败
			- 4、获取锁成功的程序，在业务执行完后删除该数据表示释放锁

	- 基于数据库排他锁

		- 实现步骤

			- 1、在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁，当某条记录被加上排他锁之后，其他线程无法再在该记录上增加排他锁
			- 2、获得排他锁的线程即可获得分布式锁，执行方法的业务逻辑
			- 3、执行完成之后，通过connection.commit()方法来释放锁

- 基于缓存（Redis等）实现

	- 实现原理

		- 1、redis提供的SETNX key value方法，当一个线程执行setnx返回1，说明key不存在，该线程获得锁；当一个线程执行setnx返回0，说明key已经存在，则获取锁失败。
		- 2、redis提供的的EXPIRE()方法，设置key在redis中的有效期。防止系统或程序崩溃之后，无法删除key导致的死锁
		- 3、redis提供的GETSET()方法，该方法是原子的，使用该方法对锁进行延期。

- 基于Zookeeper实现

	- zookeeper相关特质

		- 有序节点

		  假如当前有一个父节点为/lock，我们可以在这个父节点下面创建子节点；zookeeper提供了一个可选的有序特性，例如我们可以创建子节点“/lock/node-”并且指明有序，那么zookeeper在生成子节点时会根据当前的子节点数量自动添加整数序号，也就是说如果是第一个创建的子节点，那么生成的子节点为/lock/node-0000000000，下一个节点则为/lock/node-0000000001，依次类推。

		- 临时节点

		  客户端可以建立一个临时节点，在会话结束或者会话超时后，zookeeper会自动删除该节点。

		- 事件监听

		  在读取数据时，我们可以同时对节点设置事件监听，当节点数据或结构变化时，zookeeper会通知客户端。当前zookeeper有如下四种事件：1）节点创建；2）节点删除；3）节点数据修改；4）子节点变更。

	- 原理

		- 每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。
		- 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。
		- 同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题

	- 解决的问题

		- 锁无法释放问题

		  使用Zookeeper可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在ZK中创建一个临时节点，一旦客户端获取到锁之后突然挂掉（Session连接断开），那么这个临时节点就会自动删除掉。其他客户端就可以再次获得锁

		- 非阻塞锁问题

		  使用Zookeeper可以实现阻塞的锁，客户端可以通过在ZK中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。

		- 不可重入问题

		  使用Zookeeper也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。

		- 单点问题

		  使用Zookeeper可以有效的解决单点问题，ZK是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。

- 总结

	- 理解难度

		- 数据库<缓存<zookper

	- 实现复杂度

		- 数据库<缓存<=zookeeper

	- 性能

		- 数据库<zookpeeper<缓存

	- 可靠性

		- 数据库<缓存<zookeeper

## ZooKeeper

### 应用场景

- 配置管理
- 数据发布与订阅, 类似消息队列MQ
- 统一命名服务
- 分布式协调，通知
- 集群管理
- Master选举
- 分布式锁
- 分布式队列

### 特性

- 一致性: 数据一致性, 数据按照顺序分批入库
- 原子性: 事务要么成功要么失败
- 单一视图: 客户端连接集群中的任意zk节点, 数据都是一致的
- 可靠性:每次对zk的操作状态都会保存在服务端
- 实时性: 客户端可以读取到zk服务端的最新数据

## 一致性算法

### Paxos算法

- 角色

	- Client:系统外部角色,请求发起者
	- Propser:接受Client请求，向集群提出提议(propser)，并在产生冲突时，起到冲突调节作用
	- Accpetor:提议投票和接收者，只有在形成法定人数（一般为多数派）时，提议才能最终被接受
	- Learner:提议接受者，backup，备份，对集群一致性没什么影响

- Basic Paxos

	- 步骤，阶段

		- P1a:Prepare

			- Propser提出一个提案，编号为N，此N大于这个Propser之前提出的提案编号，请求Accpetors中的多数派接受

		- P1b:Promise

			- 如果N大于此Accpetor之前接受的任何提案编号，则接受，否则拒绝

		- P2a:Accept

			- 如果达到多数派，Propser会发出Accept请求，此请求包含提案编号N，以及提案内容

		- P2b:Accepted

			- 如果Accpetor在此期间没有接受任何编号大于N的提案，则接受此提案内容，否则忽略

	- 缺点

		- 难实现
		- 效率低（2轮RPC）
		- 活锁

		  Porpser1提出提案n,在P1b阶段通过，但是在P2b之前，Porpser1提出提案n+1，这个时候Accpetor们会放弃n提案讨论n+1提案，在n+1提案到达P2b之前，Porpser1又提出n+2提案，如此循环，谁的提案都通过不了，以至活锁。
		  
		  活锁解决方案，Porpser提出提案等待一段时间。

- Multi Paxos

	- 相对于Basic Paxos的优化

		- 出现Leader（唯一的Propser），所有提案都经过Leader来提出（解决活锁），出现Leader需要竞选（只有第一次提案才需要竞选）
		- 通过提案只需要一轮RPC

### Ralf算法

集群启动时，没有leader，而是全部初始化为 follower
leader 只能退化为follower，原因显而易见，leader只会在发现有其他更高term（任期）的leader后退居二线（一般发生在脑裂合并的场景）
理解的时候可以把角色代入级别，follower，candidate，leader的升级序列，角色不会跨级别提升

- 重新定义角色

	- Leader(领袖)
	- Follower(群众)
	- Candidate（候选人）

- 划分为三个子问题

	- Leader Election(选举Leader)
	- Log Replication(同步log到其他节点)
	- SafeTy(保证安全性)

- 和Multi Paxos区别

	- raft仅允许日志最多的节点当选为leader，而multi-paxos则相反，任意节点都可以当选leader
	- raft不允许日志的空洞，这也是为了比较方便和拉平两个节点的日志方便，而multi-paxos则允许日志出现空洞

### ZAB算法

Zookeeper最终选用ZAB算法

- 两个过程

	- 广播（boardcast）

		- Zab 协议中，所有的写请求都由 leader 来处理。正常工作状态下，leader 接收请求并通过广播协议来处理

	- 恢复（recovery）

		- 当服务初次启动，或者 leader 节点挂了，系统就会进入恢复模式，直到选出了有合法数量 follower 的新 leader，然后新 leader 负责将整个系统同步到最新状态。

- 三个阶段

	- 发现(Discovery)
	- 同步(Sychronization)
	- 广播(broadcast)

- 和Ralf的相同点

	- 都使用timeout来重新选择leader
	- 采用quorum来确定整个系统的一致性(也就是对某一个值的认可),这个quorum一般实现是集群中半数以上的服务器,zookeeper里还提供了带权重的quorum实现
	- 都由leader来发起写操作
	- 都采用心跳检测存活性
	- leader election都采用先到先得的投票方式

- 和Ralf的不同点

	- zab用的是epoch和count的组合来唯一表示一个值, 而raft用的是term和index
	- zab的follower在投票给一个leader之前必须和leader的日志达成一致,而raft的follower则简单地说是谁的term高就投票给谁
	- raft协议的心跳是从leader到follower, 而zab协议则相反
	- raft协议数据只有单向地从leader到follower(成为leader的条件之一就是拥有最新的log), 而zab协议在discovery阶段, 一个prospective leader需要将自己的log更新为quorum里面最新的log,然后才好在synchronization阶段将quorum里的其他机器的log都同步到一致

*XMind - Trial Version*